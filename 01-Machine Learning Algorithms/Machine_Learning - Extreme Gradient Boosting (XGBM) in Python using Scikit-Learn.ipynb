{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Santander Customer Transaction Prediction - XGBM\n",
    "\n",
    "#In the Kaggle competition, the objective is to identify which customer will make a transaction in the \n",
    "#future.\n",
    "\n",
    "#Link to the competition: https://www.kaggle.com/c/santander-customer-transaction-prediction/\n",
    "#Type of Problem: Classification\n",
    "#Metric for evalution: AOC (Area Under Curve)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import xgboost\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Step1: Read Training Data from CSV\n",
    "\n",
    "#Use pandas read_csv function to read train.csv\n",
    "\n",
    "df_train = pd.read_csv('E:/datafiles/santander-customer-transaction-prediction/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Separate the data into independent and dependent variables.\n",
    "#Use sklearn's train_test_split function to separate the data into training and validation data\n",
    "\n",
    "\n",
    "var_columns = [c for c in df_train.columns if c not in ['ID_code','target']]\n",
    "\n",
    "X = df_train.loc[:,var_columns]\n",
    "y = df_train.loc[:,'target']\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape, X_valid.shape, y_train.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#2.Create XGBoost Model\n",
    "\n",
    "xgboost.XGBClassifier().get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_xgboost = xgboost.XGBClassifier(learning_rate=0.1,\n",
    "                                      max_depth=5,\n",
    "                                      n_estimators=5000,\n",
    "                                      subsample=0.5,\n",
    "                                      colsample_bytree=0.5,\n",
    "                                      eval_metric='auc',\n",
    "                                      verbosity=1)\n",
    "\n",
    "eval_set = [(X_valid, y_valid)]\n",
    "\n",
    "model_xgboost.fit(X_train,\n",
    "                  y_train,\n",
    "                  early_stopping_rounds=10,\n",
    "                  eval_set=eval_set,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#3.Evaluate Model Performance\n",
    "\n",
    "y_train_pred = model_xgboost.predict_proba(X_train)[:,1]\n",
    "y_valid_pred = model_xgboost.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print(\"AUC Train: {:.4f}\\nAUC Valid: {:.4f}\".format(roc_auc_score(y_train, y_train_pred),\n",
    "                                                    roc_auc_score(y_valid, y_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#4. Hyperparameter Tuning\n",
    "\n",
    "#We will use GridSearchCV for hyperparameter tuning. As the first step, let us define all the possible\n",
    "#hyperparameter values which we want to check.\n",
    "\n",
    "learning_rate_list = [0.02, 0.05, 0.1]\n",
    "max_depth_list = [2, 3, 5]\n",
    "n_estimators_list = [1000, 2000, 3000]\n",
    "\n",
    "params_dict = {\"learning_rate\": learning_rate_list,\n",
    "               \"max_depth\": max_depth_list,\n",
    "               \"n_estimators\": n_estimators_list}\n",
    "\n",
    "num_combinations = 1\n",
    "for v in params_dict.values(): num_combinations *= len(v) \n",
    "\n",
    "print(num_combinations)\n",
    "params_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let us pass this to GridSearchCV. We have a custom scoring function based on sklearn's roc_auc_score()\n",
    "#which calculated area under the curve. CV value is 2, which is not ideal but we want to minimize the \n",
    "#execution time.\n",
    "\n",
    "def my_roc_auc_score(model, X, y): return roc_auc_score(y, model.predict_proba(X)[:,1])\n",
    "\n",
    "model_xgboost_hp = GridSearchCV(estimator=xgboost.XGBClassifier(subsample=0.5,\n",
    "                                                                colsample_bytree=0.25,\n",
    "                                                                eval_metric='auc',\n",
    "                                                                use_label_encoder=False),\n",
    "                                param_grid=params_dict,\n",
    "                                cv=2,\n",
    "                                scoring=my_roc_auc_score,\n",
    "                                return_train_score=True,\n",
    "                                verbose=4)\n",
    "\n",
    "model_xgboost_hp.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us look at the output of grid search step. We will retain only a few relevant columns and sort based\n",
    "#on rank_test_score i.ee the performance on validation data.\n",
    "\n",
    "df_cv_results = pd.DataFrame(model_xgboost_hp.cv_results_)\n",
    "df_cv_results = df_cv_results[['rank_test_score','mean_test_score','mean_train_score',\n",
    "                               'param_learning_rate', 'param_max_depth', 'param_n_estimators']]\n",
    "df_cv_results.sort_values(by='rank_test_score', inplace=True)\n",
    "df_cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us try to find how does model perfomance vary with respect to number of trees and depth of tree.\n",
    "\n",
    "# First sort by number of estimators as that would be x-axis\n",
    "\n",
    "df_cv_results.sort_values(by='param_n_estimators', inplace=True)\n",
    "\n",
    "# Find values of AUC for learning rate of 0.05 and different values of depth\n",
    "lr_d2 = df_cv_results.loc[(df_cv_results['param_learning_rate']==0.05) & (df_cv_results['param_max_depth']==2),:]\n",
    "lr_d3 = df_cv_results.loc[(df_cv_results['param_learning_rate']==0.05) & (df_cv_results['param_max_depth']==3),:]\n",
    "lr_d5 = df_cv_results.loc[(df_cv_results['param_learning_rate']==0.05) & (df_cv_results['param_max_depth']==5),:]\n",
    "lr_d7 = df_cv_results.loc[(df_cv_results['param_learning_rate']==0.05) & (df_cv_results['param_max_depth']==7),:]\n",
    "\n",
    "# Let us plot now\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "lr_d2.plot(x='param_n_estimators', y='mean_test_score', label='Depth=2', ax=ax)\n",
    "lr_d3.plot(x='param_n_estimators', y='mean_test_score', label='Depth=3', ax=ax)\n",
    "lr_d5.plot(x='param_n_estimators', y='mean_test_score', label='Depth=5', ax=ax)\n",
    "lr_d7.plot(x='param_n_estimators', y='mean_test_score', label='Depth=7', ax=ax)\n",
    "plt.ylabel('Mean Validation AUC')\n",
    "plt.title('Performance wrt # of Trees and Depth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that we have seen the performance is higher for higher values of trees and lower depth, let us find\n",
    "#performance w.r.t. learning rate. We fix n_estimators to 3000 and depth to 2.\n",
    "\n",
    "# First sort by learning rate as that would be x-axis\n",
    "df_cv_results.sort_values(by='param_learning_rate', inplace=True)\n",
    "\n",
    "# Find values of AUC for learning rate of 0.05 and different values of depth\n",
    "lr_t3k_d2 = df_cv_results.loc[(df_cv_results['param_n_estimators']==3000) & (df_cv_results['param_max_depth']==2),:]\n",
    "\n",
    "# Let us plot now\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "lr_t3k_d2.plot(x='param_learning_rate', y='mean_test_score', label='Depth=2, Trees=3000', ax=ax)\n",
    "plt.ylabel('Mean Validation AUC')\n",
    "plt.title('Performance wrt learning rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5. Final Model\n",
    "\n",
    "#With Best Hyper Parameters from the above step\n",
    "\n",
    "model_xgboost_fin = xgboost.XGBClassifier(learning_rate=0.05,\n",
    "                                          max_depth=2,\n",
    "                                          n_estimators=5000,\n",
    "                                          subsample=0.5,\n",
    "                                          colsample_bytree=0.25,\n",
    "                                          eval_metric='auc',\n",
    "                                          verbosity=1,\n",
    "                                          use_label_encoder=False)\n",
    "\n",
    "# Passing both training and validation dataset as we want to plot AUC for both\n",
    "eval_set = [(X_train, y_train),(X_valid, y_valid)]\n",
    "\n",
    "model_xgboost_fin.fit(X_train,\n",
    "                  y_train,\n",
    "                  early_stopping_rounds=20,\n",
    "                  eval_set=eval_set,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now find out the performance of the final model by calculating AUC value on training and validation sets.\n",
    "\n",
    "y_train_pred = model_xgboost_fin.predict_proba(X_train)[:,1]\n",
    "y_valid_pred = model_xgboost_fin.predict_proba(X_valid)[:,1]\n",
    "\n",
    "print(\"AUC Train: {:.4f}\\nAUC Valid: {:.4f}\".format(roc_auc_score(y_train, y_train_pred),\n",
    "                                                    roc_auc_score(y_valid, y_valid_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us print model performance w.r.t number of trees. The first step is to get AUC values on training\n",
    "#and validation dataset for every value of the tree. We can use eval_result() function to get that. \n",
    "#Then we can go ahead and plot it.\n",
    "\n",
    "evaluation_results = model_xgboost_fin.evals_result()\n",
    "\n",
    "# Index into each key to find AUC values for training and validation data after each tree\n",
    "train_auc_tree = evaluation_results['validation_0']['auc']\n",
    "valid_auc_tree = evaluation_results['validation_1']['auc']\n",
    "\n",
    "\n",
    "# Plotting Section\n",
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.plot(train_auc_tree, label='Train')\n",
    "plt.plot(valid_auc_tree, label='valid')\n",
    "\n",
    "plt.title(\"Train and validation AUC as number of trees increase\")\n",
    "plt.xlabel(\"Trees\")\n",
    "plt.ylabel(\"AUC\")\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let us also look at variable importance\n",
    "\n",
    "df_var_imp = pd.DataFrame({\"Variable\": var_colums,\n",
    "                           \"Importance\": model_xgboost_fin.feature_importances_}) \\\n",
    "                        .sort_values(by='Importance', ascending=False)\n",
    "df_var_imp[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6. Score the test data\n",
    "\n",
    "#First let us import test.csv\n",
    "\n",
    "df_test = pd.read_csv('E:/datafiles/santander-customer-transaction-prediction/test.csv')\n",
    "df_sample_submission = pd.read_csv('E:/datafiles/santander-customer-transaction-prediction/sample_submission.csv')\n",
    "\n",
    "df_test.shape, df_sample_submission.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
