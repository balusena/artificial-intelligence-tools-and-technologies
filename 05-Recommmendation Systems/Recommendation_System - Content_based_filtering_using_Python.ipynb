{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Broadly, recommender systems can be classified into 3 types:\n",
    "\n",
    "#1.Simple recommenders:offer generalized recommendations to every user,based on movie popularity and/or\n",
    "#genre.The basic idea behind this system is that movies that are more popular and critically acclaimed \n",
    "#will have a higher probability of being liked by the average audience. An example could be IMDB Top 250.\n",
    "\n",
    "#2.Content-based recommenders: suggest similar items based on a particular item. This system uses item \n",
    "#metadata, such as genre, director, description, actors, etc. for movies, to make these recommendations. \n",
    "#The general idea behind these recommender systems is that if a person likes a particular item, he or \n",
    "#she will also like an item that is similar to it. And to recommend that, it will make use of the user's\n",
    "#past item metadata. A good example could be YouTube, where based on your history, it suggests you new \n",
    "#videos that you could potentially watch.\n",
    "\n",
    "#3.Collaborative filtering engines: these systems are widely used, and they try to predict the rating or \n",
    "#preference that a user would give an item-based on past ratings and preferences of other users.\n",
    "#Collaborative filters do not require item metadata like its content-based counterparts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>[{'id': 12, 'name': 'Adventure'}, {'id': 14, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-15</td>\n",
       "      <td>262797249.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>[{'id': 10749, 'name': 'Romance'}, {'id': 35, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-12-22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1  False                                                NaN  65000000   \n",
       "2  False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "1  [{'id': 12, 'name': 'Adventure'}, {'id': 14, '...   \n",
       "2  [{'id': 10749, 'name': 'Romance'}, {'id': 35, ...   \n",
       "\n",
       "                               homepage     id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story    862  tt0114709                en   \n",
       "1                                   NaN   8844  tt0113497                en   \n",
       "2                                   NaN  15602  tt0113228                en   \n",
       "\n",
       "     original_title                                           overview  ...  \\\n",
       "0         Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "1           Jumanji  When siblings Judy and Peter discover an encha...  ...   \n",
       "2  Grumpier Old Men  A family wedding reignites the ancient feud be...  ...   \n",
       "\n",
       "  release_date      revenue runtime  \\\n",
       "0   1995-10-30  373554033.0    81.0   \n",
       "1   1995-12-15  262797249.0   104.0   \n",
       "2   1995-12-22          0.0   101.0   \n",
       "\n",
       "                                    spoken_languages    status  \\\n",
       "0           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1  [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "2           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "                                             tagline             title  video  \\\n",
       "0                                                NaN         Toy Story  False   \n",
       "1          Roll the dice and unleash the excitement!           Jumanji  False   \n",
       "2  Still Yelling. Still Fighting. Still Ready for...  Grumpier Old Men  False   \n",
       "\n",
       "  vote_average vote_count  \n",
       "0          7.7     5415.0  \n",
       "1          6.9     2413.0  \n",
       "2          6.5       92.0  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1.Simple Recommenders:-\n",
    "\n",
    "#Simple recommenders are basic systems that recommend the top items based on a certain metric or score. \n",
    "#In this section, you will build a simplified clone of IMDB Top 250 Movies using metadata collected from\n",
    "#IMDB.\n",
    "\n",
    "#The following are the steps involved:\n",
    "\n",
    "#1.Decide on the metric or score to rate movies on.\n",
    "\n",
    "#2.Calculate the score for every movie.\n",
    "\n",
    "#3.Sort the movies based on the score and output the top results.\n",
    "\n",
    "#Load your movies metadata dataset into a pandas DataFrame:\n",
    "\n",
    "# Import Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Load Movies Metadata\n",
    "metadata = pd.read_csv('E:/datafiles/ml-latest-full/movies_metadata.csv', low_memory=False)\n",
    "\n",
    "# Print the first three rows\n",
    "metadata.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.618207215134185\n"
     ]
    }
   ],
   "source": [
    "#One of the most basic metrics you can think of is the ranking to decide which top 250 movies are based\n",
    "#on their respective ratings.\n",
    "\n",
    "#However, using a rating as a metric has a few caveats:\n",
    "\n",
    "#For one, it does not take into consideration the popularity of a movie. Therefore, a movie with a rating\n",
    "#of 9 from 10 voters will be considered 'better' than a movie with a rating of 8.9 from 10,000 voters.\n",
    "\n",
    "#What if,we have to consider multiple movies and users at the same time t0 choose the ratings then,taking \n",
    "#these shortcomings into consideration, you must come up with a weighted rating that takes into account \n",
    "#the average rating and the number of votes it has accumulated.\n",
    "\n",
    "#Since you are trying to build a clone of IMDB's Top 250,let's use its weighted rating formula as a \n",
    "#metric/score. WeightedRating(WR) = (v/(v+m)*R)+(m/(v+m)*C)\n",
    "\n",
    "#v is the number of votes for the movie;\n",
    "\n",
    "#m is the minimum votes required to be listed in the chart;\n",
    "\n",
    "#R is the average rating of the movie;\n",
    "\n",
    "#C is the mean vote across the whole report.\n",
    "\n",
    "#You already have the values to v (vote_count) and R (vote_average) for each movie in the dataset. \n",
    "#It is also possible to directly calculate C from this data.\n",
    "\n",
    "#Since there is no right value for 'm' we will use cutoff m as the 90th percentile in other words\n",
    "#remove the movies which have a number of votes less than a certain threshold 'm' value i.e 90th\n",
    "#percentile\n",
    "\n",
    "#Let's calculate the value of C, the mean rating across all movies using the pandas .mean() function:\n",
    "\n",
    "# Calculate mean of vote average column\n",
    "C = metadata['vote_average'].mean()\n",
    "print(C)\n",
    "\n",
    "#Note:- We observe that the average rating of a movie on IMDB is around 5.6 on a scale of 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160.0\n"
     ]
    }
   ],
   "source": [
    "#let's calculate the number of votes, m, received by a movie in the 90th percentile by using using the \n",
    "#pandas .quantile() function:\n",
    "\n",
    "# Calculate the minimum number of votes required to be in the chart, m\n",
    "m = metadata['vote_count'].quantile(0.90)\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4555, 24)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now you have the m you can simply use a greater than equal to condition to filter out movies having \n",
    "#greater than equal to 160 vote counts:\n",
    "\n",
    "#You can use the .copy() method to ensure that the new q_movies DataFrame created is independent of \n",
    "#your original metadata DataFrame.which does not effect the original dataframe.\n",
    "\n",
    "# Filter out all qualified movies into a new DataFrame\n",
    "q_movies = metadata.copy().loc[metadata['vote_count'] >= m]\n",
    "q_movies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45466, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.shape\n",
    "\n",
    "#Note:- From above o/p It is clear that there are around 10% movies with vote count more than 160 and \n",
    "#qualify to be on this list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next and the most important step is to calculate the weighted rating for each qualified movie:\n",
    "#To do this, we will:\n",
    "\n",
    "#1.Define a function, weighted_rating();\n",
    "\n",
    "#2.Since you already have calculated m and C you will simply pass them as an argument to the function;\n",
    "\n",
    "#3.Then you will select the vote_count(v) and vote_average(R) column from the q_movies data frame;\n",
    "\n",
    "#4.Finally, you will compute the weighted average and return the result.\n",
    "\n",
    "#We will define a new feature score, of which you'll calculate the value by applying this function to \n",
    "#your DataFrame of qualified movies:\n",
    "\n",
    "# Function that computes the weighted rating of each movie\n",
    "def weighted_rating(x, m=m, C=C):\n",
    "    v = x['vote_count']\n",
    "    R = x['vote_average']\n",
    "    # Calculation based on the IMDB formula\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a new feature 'score' and calculate its value with `weighted_rating()`\n",
    "q_movies['score'] = q_movies.apply(weighted_rating, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>8358.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.445869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>834</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>6024.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.425439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10309</th>\n",
       "      <td>Dilwale Dulhania Le Jayenge</td>\n",
       "      <td>661.0</td>\n",
       "      <td>9.1</td>\n",
       "      <td>8.421453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12481</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>12269.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.265477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2843</th>\n",
       "      <td>Fight Club</td>\n",
       "      <td>9678.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.256385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>Pulp Fiction</td>\n",
       "      <td>8670.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.251406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>Schindler's List</td>\n",
       "      <td>4436.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.206639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23673</th>\n",
       "      <td>Whiplash</td>\n",
       "      <td>4376.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.205404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5481</th>\n",
       "      <td>Spirited Away</td>\n",
       "      <td>3968.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.196055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2211</th>\n",
       "      <td>Life Is Beautiful</td>\n",
       "      <td>3643.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.187171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1178</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>3418.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.180076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>One Flew Over the Cuckoo's Nest</td>\n",
       "      <td>3001.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.164256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>8147.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.150272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>The Empire Strikes Back</td>\n",
       "      <td>5998.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.132919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>2405.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.132715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18465</th>\n",
       "      <td>The Intouchables</td>\n",
       "      <td>5410.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.125837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40251</th>\n",
       "      <td>Your Name.</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>8.112532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>Leon: The Professional</td>\n",
       "      <td>4293.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.107234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3030</th>\n",
       "      <td>The Green Mile</td>\n",
       "      <td>4166.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.104511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1170</th>\n",
       "      <td>GoodFellas</td>\n",
       "      <td>3211.0</td>\n",
       "      <td>8.2</td>\n",
       "      <td>8.077459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 title  vote_count  vote_average     score\n",
       "314           The Shawshank Redemption      8358.0           8.5  8.445869\n",
       "834                      The Godfather      6024.0           8.5  8.425439\n",
       "10309      Dilwale Dulhania Le Jayenge       661.0           9.1  8.421453\n",
       "12481                  The Dark Knight     12269.0           8.3  8.265477\n",
       "2843                        Fight Club      9678.0           8.3  8.256385\n",
       "292                       Pulp Fiction      8670.0           8.3  8.251406\n",
       "522                   Schindler's List      4436.0           8.3  8.206639\n",
       "23673                         Whiplash      4376.0           8.3  8.205404\n",
       "5481                     Spirited Away      3968.0           8.3  8.196055\n",
       "2211                 Life Is Beautiful      3643.0           8.3  8.187171\n",
       "1178            The Godfather: Part II      3418.0           8.3  8.180076\n",
       "1152   One Flew Over the Cuckoo's Nest      3001.0           8.3  8.164256\n",
       "351                       Forrest Gump      8147.0           8.2  8.150272\n",
       "1154           The Empire Strikes Back      5998.0           8.2  8.132919\n",
       "1176                            Psycho      2405.0           8.3  8.132715\n",
       "18465                 The Intouchables      5410.0           8.2  8.125837\n",
       "40251                       Your Name.      1030.0           8.5  8.112532\n",
       "289             Leon: The Professional      4293.0           8.2  8.107234\n",
       "3030                    The Green Mile      4166.0           8.2  8.104511\n",
       "1170                        GoodFellas      3211.0           8.2  8.077459"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's sort the DataFrame in descending order based on the score feature column and output the title, \n",
    "#vote count, vote average, and weighted rating (score) of the top 20 movies.\n",
    "\n",
    "#Sort movies based on score calculated above\n",
    "q_movies = q_movies.sort_values('score', ascending=False)\n",
    "\n",
    "#Print the top 15 movies\n",
    "q_movies[['title', 'vote_count', 'vote_average', 'score']].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Led by Woody, Andy's toys live happily in his ...\n",
       "1    When siblings Judy and Peter discover an encha...\n",
       "2    A family wedding reignites the ancient feud be...\n",
       "3    Cheated on, mistreated and stepped on, the wom...\n",
       "4    Just when George Banks has recovered from his ...\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2.Content-Based Recommender\n",
    "\n",
    "#Plot Description Based Recommender:\n",
    "\n",
    "#We will learn how to build a system that recommends movies that are similar to a particular movie. \n",
    "#To achieve this, you will compute pairwise cosine similarity scores for all movies based on their \n",
    "#plot descriptions and recommend movies based on that similarity score threshold.\n",
    "\n",
    "#The plot description is available to you as the overview feature in your metadata dataset.Let's inspect \n",
    "#the plots of a few movies:\n",
    "\n",
    "#Print plot overviews of the first 5 movies.\n",
    "metadata['overview'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45466, 75827)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The problem at hand is a Natural Language Processing problem,and it is not possible to compute the \n",
    "#similarity between any two overviews in their raw forms. To do this, you need to compute the word \n",
    "#vectors of each overview or document\n",
    "\n",
    "#word vectors are vectorized representation of words in a document.The vectors carry a semantic meaning\n",
    "#with it. For example, man & king will have vector representations close to each other while man & woman\n",
    "#would have representation far from each other.\n",
    "\n",
    "#We will compute Term Frequency-Inverse Document Frequency (TF-IDF) vectors for each document by this we\n",
    "#will get a matrix where each column represents a word in the overview vocabulary (all the words that \n",
    "#appear in at least one document), and each column represents a movie, as before.\n",
    "\n",
    "#The TF-IDF score is the frequency of a word occurring in a document, down-weighted by the number of \n",
    "#documents in which it occurs. This is done to reduce the importance of words that frequently occur \n",
    "#in plot overviews and, therefore, their significance in computing the final similarity score.\n",
    "\n",
    "#Fortunately, scikit-learn gives you a built-in TfIdfVectorizer class that produces the TF-IDF matrix \n",
    "#in a couple of lines.\n",
    "\n",
    "#1.Import the Tfidf module using scikit-learn;\n",
    "\n",
    "#2.Remove stop words like 'the', 'an', etc. since they do not give any useful information about the topic;\n",
    "\n",
    "#3.Replace not-a-number values with a blank string;\n",
    "\n",
    "#4.Finally, construct the TF-IDF matrix on the data.\n",
    "\n",
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "metadata['overview'] = metadata['overview'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(metadata['overview'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['avails',\n",
       " 'avaks',\n",
       " 'avalanche',\n",
       " 'avalanches',\n",
       " 'avallone',\n",
       " 'avalon',\n",
       " 'avant',\n",
       " 'avanthika',\n",
       " 'avanti',\n",
       " 'avaracious']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Array mapping from feature integer indices to feature name.\n",
    "tfidf.get_feature_names()[5000:5010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the above output, you observe that 75,827 different vocabularies or words in your dataset have \n",
    "#45,000 movies.\n",
    "\n",
    "#With this matrix in hand, you can now compute a similarity score.There are several similarity metrics\n",
    "#that you can use for this,such as the manhattan,euclidean,the Pearson,and the cosine similarity scores. \n",
    "#Again, there is no right answer to which score is the best. Different scores work well in different \n",
    "#scenarios, and it is often a good idea to experiment with different metrics and observe the results.\n",
    "\n",
    "#Cosine Similarity = x * y/|x|*|y|\n",
    "\n",
    "#Since you have used the TF-IDF vectorizer,calculating the dot product between each vector will directly\n",
    "#give you the cosine similarity score.Therefore, you will use sklearn's linear_kernel() instead of \n",
    "#cosine_similarities() since it is faster.\n",
    "\n",
    "#This would return a matrix of shape 45466x45466, which means each movie overview cosine similarity score \n",
    "#with every other movie overview.Hence, each movie will be a 1x45466 column vector where each column will \n",
    "#be a similarity score with each movie.\n",
    "\n",
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45466, 45466)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01504121, 1.        , 0.04681953, ..., 0.        , 0.02198641,\n",
       "       0.00929411])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You're going to define a function that takes in a movie title as an input and outputs a list of the 10 \n",
    "#most similar movies.\n",
    "\n",
    "#Firstly, for this, you need a reverse mapping of movie titles and DataFrame indices.\n",
    "\n",
    "#In other words,you need a mechanism to identify the index of a movie in your metadata DataFrame,given \n",
    "#its title.\n",
    "\n",
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(metadata.index, index=metadata['title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "Toy Story                      0\n",
       "Jumanji                        1\n",
       "Grumpier Old Men               2\n",
       "Waiting to Exhale              3\n",
       "Father of the Bride Part II    4\n",
       "Heat                           5\n",
       "Sabrina                        6\n",
       "Tom and Huck                   7\n",
       "Sudden Death                   8\n",
       "GoldenEye                      9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are in good shape to define our recommendation function.these are the following steps we follow:- \n",
    "\n",
    "#1.Get the index of the movie given its title.\n",
    "\n",
    "#2.Get the list of cosine similarity scores for that particular movie with all movies. Convert it into a list of tuples where the first element is its position, and the second is the similarity score.\n",
    "\n",
    "#3.Sort the aforementioned list of tuples based on the similarity scores; that is, the second element.\n",
    "\n",
    "#4.Get the top 10 elements of this list.Ignore the first element as it refers to self (the movie most \n",
    "#similar to a particular movie is the movie itself).\n",
    "\n",
    "#5.Return the titles corresponding to the indices of the top elements.\n",
    "\n",
    "\n",
    "# Function that takes in movie title as input and outputs most similar movies\n",
    "def get_recommendations(title, cosine_sim=cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "    idx = indices[title]\n",
    "\n",
    "    # Get the pairwsie similarity scores of all movies with that movie\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "\n",
    "    # Sort the movies based on the similarity scores\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Get the scores of the 10 most similar movies\n",
    "    sim_scores = sim_scores[1:11]\n",
    "\n",
    "    # Get the movie indices\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return metadata['title'].iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12481                                      The Dark Knight\n",
       "150                                         Batman Forever\n",
       "1328                                        Batman Returns\n",
       "15511                           Batman: Under the Red Hood\n",
       "585                                                 Batman\n",
       "21194    Batman Unmasked: The Psychology of the Dark Kn...\n",
       "9230                    Batman Beyond: Return of the Joker\n",
       "18035                                     Batman: Year One\n",
       "19792              Batman: The Dark Knight Returns, Part 1\n",
       "3095                          Batman: Mask of the Phantasm\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Dark Knight Rises')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1178               The Godfather: Part II\n",
       "44030    The Godfather Trilogy: 1972-1990\n",
       "1914              The Godfather: Part III\n",
       "23126                          Blood Ties\n",
       "11297                    Household Saints\n",
       "34717                   Start Liquidation\n",
       "10821                            Election\n",
       "38030            A Mother Should Be Loved\n",
       "17729                   Short Sharp Shock\n",
       "26293                  Beck 28 - Familjen\n",
       "Name: title, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('The Godfather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note:- You see that, while your system has done a decent job of finding movies with similar plot \n",
    "#descriptions, the quality of recommendations is not that great. \"The Dark Knight Rises\" returns all\n",
    "#Batman movies while it is more likely that the people who liked that movie are more inclined to enjoy\n",
    "#other Christopher Nolan movies. his is something that cannot be captured by your present system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'[19730 29503 35587] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-7569fb6018dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Remove rows with bad IDs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m19730\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m29503\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m35587\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# Convert IDs to int. Required for merging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3988\u001b[0m                 \u001b[0mweight\u001b[0m  \u001b[1;36m1.0\u001b[0m     \u001b[1;36m0.8\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3989\u001b[0m         \"\"\"\n\u001b[1;32m-> 3990\u001b[1;33m         return super().drop(\n\u001b[0m\u001b[0;32m   3991\u001b[0m             \u001b[0mlabels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3992\u001b[0m             \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   3934\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3935\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3936\u001b[1;33m                 \u001b[0mobj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[1;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[0;32m   3968\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3969\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3970\u001b[1;33m                 \u001b[0mnew_axis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3971\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\lenovo\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mdrop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   5016\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5017\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5018\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5019\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5020\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: '[19730 29503 35587] not found in axis'"
     ]
    }
   ],
   "source": [
    "#Credits, Genres, and Keywords Based Recommender\n",
    "\n",
    "#You will build a recommender system based on the following metadata:the 3 top actors,the director,related \n",
    "#genres, and the movie plot keywords.\n",
    "\n",
    "#The keywords,cast, and crew data are not available in your current dataset,so the first step would be to \n",
    "#load and merge them into your main DataFrame metadata.\n",
    "\n",
    "credits = pd.read_csv('E:/datafiles/ml-latest-full/credits.csv')\n",
    "keywords = pd.read_csv('E:/datafiles/ml-latest-full/keywords.csv')\n",
    "\n",
    "# Remove rows with bad IDs.\n",
    "metadata = metadata.drop([19730, 29503, 35587])\n",
    "\n",
    "# Convert IDs to int. Required for merging\n",
    "keywords['id'] = keywords['id'].astype('int')\n",
    "credits['id'] = credits['id'].astype('int')\n",
    "metadata['id'] = metadata['id'].astype('int')\n",
    "\n",
    "# Merge keywords and credits into your main metadata dataframe\n",
    "metadata = metadata.merge(credits, on = 'id')\n",
    "metadata = metadata.merge(keywords, on = 'id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
